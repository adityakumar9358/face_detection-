{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b32fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition as fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c879da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.633] global /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_11nitadzeg/croot/opencv-suite_1691620374638/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1617e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = fr.load_image_file('aditya.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c67148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_face_encoding = fr.face_encodings(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6335f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = [image_face_encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4de2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_names = [\"ADITYA KUMAR PANDEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd81b348",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x1404454b0>, array([[[123, 121, 117],\n        [116, 114, 110],\n        [123, 121, 117],\n        ...,\n        [ 46,  27,  17],\n        [ 48,  29,  22],\n        [ 43,  23,  16]],\n\n       [[119, 118, 113],\n        [117, 115, 111],\n        [123, 121, 117],\n        ...,\n        [ 46,  27,  15],\n        [ 50,  30,  21],\n        [ 40,  21,  12]],\n\n       [[124, 122, 118],\n        [120, 119, 114],\n        [121, 120, 115],\n        ...,\n        [ 58,  39,  27],\n        [ 51,  32,  22],\n        [ 41,  22,  13]],\n\n       ...,\n\n       [[119, 112,  86],\n        [115, 109,  83],\n        [121, 115,  89],\n        ...,\n        [185, 141, 121],\n        [185, 141, 121],\n        [186, 142, 123]],\n\n       [[115, 109,  83],\n        [115, 109,  83],\n        [118, 111,  85],\n        ...,\n        [182, 139, 119],\n        [183, 140, 120],\n        [185, 141, 121]],\n\n       [[115, 109,  83],\n        [116, 110,  84],\n        [115, 109,  83],\n        ...,\n        [183, 140, 120],\n        [180, 137, 117],\n        [180, 137, 117]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x10500d8f0>, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m frame[ :,:, :: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m fc_locations \u001b[38;5;241m=\u001b[39m  fr\u001b[38;5;241m.\u001b[39mface_locations(rgb_frame)\n\u001b[0;32m----> 8\u001b[0m fc_encodings \u001b[38;5;241m=\u001b[39m fr\u001b[38;5;241m.\u001b[39mface_encodings(rgb_frame, fc_locations)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m(top, right, bottom, left), face_encoding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fc_locations, face_encodings):\n\u001b[1;32m     11\u001b[0m     mathces \u001b[38;5;241m=\u001b[39m fr\u001b[38;5;241m.\u001b[39mcomapre_faces(known_face_encodings, face_encoding)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/face_recognition/api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[0;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/face_recognition/api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x1404454b0>, array([[[123, 121, 117],\n        [116, 114, 110],\n        [123, 121, 117],\n        ...,\n        [ 46,  27,  17],\n        [ 48,  29,  22],\n        [ 43,  23,  16]],\n\n       [[119, 118, 113],\n        [117, 115, 111],\n        [123, 121, 117],\n        ...,\n        [ 46,  27,  15],\n        [ 50,  30,  21],\n        [ 40,  21,  12]],\n\n       [[124, 122, 118],\n        [120, 119, 114],\n        [121, 120, 115],\n        ...,\n        [ 58,  39,  27],\n        [ 51,  32,  22],\n        [ 41,  22,  13]],\n\n       ...,\n\n       [[119, 112,  86],\n        [115, 109,  83],\n        [121, 115,  89],\n        ...,\n        [185, 141, 121],\n        [185, 141, 121],\n        [186, 142, 123]],\n\n       [[115, 109,  83],\n        [115, 109,  83],\n        [118, 111,  85],\n        ...,\n        [182, 139, 119],\n        [183, 140, 120],\n        [185, 141, 121]],\n\n       [[115, 109,  83],\n        [116, 110,  84],\n        [115, 109,  83],\n        ...,\n        [183, 140, 120],\n        [180, 137, 117],\n        [180, 137, 117]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x10500d8f0>, 1"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "        \n",
    "        ret , frame = video_capture.read()\n",
    "        \n",
    "        rgb_frame = frame[ :,:, :: -1]\n",
    "        \n",
    "        fc_locations =  fr.face_locations(rgb_frame)\n",
    "        fc_encodings = fr.face_encodings(rgb_frame, fc_locations)\n",
    "        \n",
    "        for(top, right, bottom, left), face_encoding in zip(fc_locations, face_encodings):\n",
    "            mathces = fr.comapre_faces(known_face_encodings, face_encoding)\n",
    "            \n",
    "            name = \"unknow\"\n",
    "            \n",
    "            fc_distances = fr.face_distances(known_face_encodings, face_encoding)\n",
    "            \n",
    "            match_index = np.argmin(fc_distances)\n",
    "            \n",
    "            if matches[match_index]:\n",
    "                name = known_face_name[match_index]\n",
    "                \n",
    "                cv2.rectangle(frame, (left, top),(right, bottom), (0,0,255),2)\n",
    "                \n",
    "                cv2.rectangle(frame,(left, bottom -35),(right, bottom),(0,0,255), cv2.FILLED)\n",
    "                \n",
    "                font = cv2.FONT_HERSHLEY_SIMPLEX\n",
    "                \n",
    "                cv2.putText(frame, name, (left +6, bottom -6),font, 1.0,(255, 255, 255), 1)\n",
    "                \n",
    "                cv2.putText('aditya kumar pandey' , frame)\n",
    "                \n",
    "                if cv2.waitKey(1)& 0xFF== ord('q'):\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "video_capture.release()\n",
    "cv2.destroyAllwindow()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb8ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2e4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a2c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393435a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
